{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe1155a-9e14-4c47-bccb-fdb1f2604def",
   "metadata": {},
   "source": [
    "# Lab 1. Text-completion with GenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ea3b7-4e7b-4782-b35d-50fb4576ad8d",
   "metadata": {},
   "source": [
    "### Download Qwen2-7B-Instruct model from ModelScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d35c93-6341-4422-a41f-ea084d597579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading [added_tokens.json]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80.0/80.0 [00:00<00:00, 122B/s]\n",
      "Downloading [config.json]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 677/677 [00:00<00:00, 893B/s]\n",
      "Downloading [generation_config.json]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 243/243 [00:01<00:00, 132B/s]\n",
      "Downloading [merges.txt]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.59M/1.59M [00:01<00:00, 1.02MB/s]\n",
      "Downloading [openvino_detokenizer.bin]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.88M/1.88M [00:00<00:00, 2.28MB/s]\n",
      "Downloading [openvino_detokenizer.xml]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.95k/4.95k [00:00<00:00, 6.64kB/s]\n",
      "Downloading [openvino_model.bin]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.81G/4.81G [00:48<00:00, 107MB/s]\n",
      "Downloading [openvino_model.xml]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.20M/3.20M [00:02<00:00, 1.63MB/s]\n",
      "Downloading [openvino_tokenizer.bin]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.91M/3.91M [00:01<00:00, 4.05MB/s]\n",
      "Downloading [openvino_tokenizer.xml]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26.3k/26.3k [00:00<00:00, 29.7kB/s]\n",
      "Downloading [special_tokens_map.json]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 367/367 [00:00<00:00, 421B/s]\n",
      "Downloading [tokenizer.json]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6.70M/6.70M [00:02<00:00, 3.12MB/s]\n",
      "Downloading [tokenizer_config.json]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.27k/1.27k [00:00<00:00, 1.72kB/s]\n",
      "Downloading [vocab.json]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.65M/2.65M [00:01<00:00, 1.44MB/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "llm_model_id = \"snake7gun/Qwen2-7B-Instruct-int4-ov\"\n",
    "llm_local_path  = \"./model/\" + llm_model_id\n",
    "\n",
    "if not Path(llm_local_path).exists():\n",
    "    model_dir = snapshot_download(llm_model_id, cache_dir=\"./model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e8764-25a6-4d42-8a8e-30e0db792199",
   "metadata": {},
   "source": [
    "### Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ebf4f1-a5b3-4c9a-a98f-bc885ebf6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino_genai as ov_genai\n",
    "\n",
    "pipe = ov_genai.LLMPipeline(llm_local_path, \"GPU\")\n",
    "\n",
    "def streamer(subword):\n",
    "    print(subword, end='', flush=True)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f06970-6bc2-4e50-85fe-cc49c35c31dd",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef4d999-04c7-4b1a-ad42-1b2e6cdc4bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO（Open Visual Inference and Neural Network Optimization）是由英特尔开发的一套开源工具套件，用于在各种设备上部署深度学习模型。它提供了一个API库和一组工具，用于优化神经网络模型的性能，并在不同的硬件平台上进行推理。\n",
      "\n",
      "OpenVINO的主要功能包括：\n",
      "\n",
      "1. **模型优化**：它能够优化神经网络模型，以适应不同的硬件平台，包括CPU、GPU、VPU（Vision Processing Unit）等。优化过程包括模型转换、量化、并行化等步骤，以提高模型的执行效率。\n",
      "\n",
      "2. **推理引擎**：OpenVINO提供了一个高性能的推理引擎，用于在各种硬件平台上执行模型推理。它支持多种硬件加速技术，如OpenCL、VPU等，以实现快速的实时推理。\n",
      "\n",
      "3. **API支持**：它提供了多种编程语言的API接口，如C++、Python等，方便开发者在不同的开发环境中使用。\n",
      "\n",
      "4. **模型库**：OpenVINO还包含了一些预训练的模型库，开发者可以直接使用这些模型进行特定任务的开发，而无需从头开始训练模型。\n",
      "\n",
      "5. **支持多种框架**：它支持多种深度学习框架，如TensorFlow、Caffe、ONNX等，使得开发者可以方便地将模型从这些框架转换到OpenVINO进行优化和部署。\n",
      "\n",
      "通过使用OpenVINO，开发者可以更高效地将深度学习模型部署到实际应用中，特别是在需要在边缘设备上进行实时推理的场景中。"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OpenVINO（Open Visual Inference and Neural Network Optimization）是由英特尔开发的一套开源工具套件，用于在各种设备上部署深度学习模型。它提供了一个API库和一组工具，用于优化神经网络模型的性能，并在不同的硬件平台上进行推理。\\n\\nOpenVINO的主要功能包括：\\n\\n1. **模型优化**：它能够优化神经网络模型，以适应不同的硬件平台，包括CPU、GPU、VPU（Vision Processing Unit）等。优化过程包括模型转换、量化、并行化等步骤，以提高模型的执行效率。\\n\\n2. **推理引擎**：OpenVINO提供了一个高性能的推理引擎，用于在各种硬件平台上执行模型推理。它支持多种硬件加速技术，如OpenCL、VPU等，以实现快速的实时推理。\\n\\n3. **API支持**：它提供了多种编程语言的API接口，如C++、Python等，方便开发者在不同的开发环境中使用。\\n\\n4. **模型库**：OpenVINO还包含了一些预训练的模型库，开发者可以直接使用这些模型进行特定任务的开发，而无需从头开始训练模型。\\n\\n5. **支持多种框架**：它支持多种深度学习框架，如TensorFlow、Caffe、ONNX等，使得开发者可以方便地将模型从这些框架转换到OpenVINO进行优化和部署。\\n\\n通过使用OpenVINO，开发者可以更高效地将深度学习模型部署到实际应用中，特别是在需要在边缘设备上进行实时推理的场景中。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\n什么是OpenVINO？<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "pipe.generate(prompt, eos_token_id=151645, max_length=500, streamer=streamer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafe9c0",
   "metadata": {},
   "source": [
    "### MiniCPM-2B-dpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b5f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "llm_model_id = \"snake7gun/minicpm-2b-dpo-int4-ov\"\n",
    "llm_local_path  = \"./model/\" + llm_model_id\n",
    "\n",
    "if not Path(llm_local_path).exists():\n",
    "    model_dir = snapshot_download(llm_model_id, cache_dir=\"./model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a8374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ov_genai.LLMPipeline(llm_local_path, \"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68ec038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO（Open Visual Inference and Neural Network Optimization）是一个由英特尔公司开发的开源计算机视觉和机器学习框架。OpenVINO的目标是加速深度学习模型在边缘设备上的部署，特别是在嵌入式设备、物联网（IoT）设备和移动设备上。\n",
      "\n",
      "OpenVINO框架提供了以下功能：\n",
      "\n",
      "1. 模型优化：通过使用英特尔的优化技术，如量化、剪枝和混合精度，将深度学习模型转换为适用于边缘设备的低资源、低功耗和低延迟模型。\n",
      "2. 推理引擎：OpenVINO提供了一种名为Inference Engine的推理引擎，它支持多种深度学习框架，如TensorFlow、PyTorch和Caffe。Inference Engine可以自动将模型转换为适用于边缘设备的低资源模型，并支持多种硬件平台，如CPU、GPU和FPGA。\n",
      "3. 工具和库：OpenVINO提供了许多工具和库，如OpenVINO Toolkit、OpenVINO SDK和OpenVINO Samples，以帮助开发者快速开始使用OpenVINO框架。\n",
      "4. 社区支持：OpenVINO有一个活跃的社区，开发者可以在这里分享经验、解决问题，并获取最新的开发工具和资源。\n",
      "\n",
      "通过使用OpenVINO，开发者可以轻松地将深度学习模型部署到边缘设备上，实现实时图像处理、语音识别、计算机视觉和自然语言处理等应用。"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OpenVINO（Open Visual Inference and Neural Network Optimization）是一个由英特尔公司开发的开源计算机视觉和机器学习框架。OpenVINO的目标是加速深度学习模型在边缘设备上的部署，特别是在嵌入式设备、物联网（IoT）设备和移动设备上。\\n\\nOpenVINO框架提供了以下功能：\\n\\n1. 模型优化：通过使用英特尔的优化技术，如量化、剪枝和混合精度，将深度学习模型转换为适用于边缘设备的低资源、低功耗和低延迟模型。\\n2. 推理引擎：OpenVINO提供了一种名为Inference Engine的推理引擎，它支持多种深度学习框架，如TensorFlow、PyTorch和Caffe。Inference Engine可以自动将模型转换为适用于边缘设备的低资源模型，并支持多种硬件平台，如CPU、GPU和FPGA。\\n3. 工具和库：OpenVINO提供了许多工具和库，如OpenVINO Toolkit、OpenVINO SDK和OpenVINO Samples，以帮助开发者快速开始使用OpenVINO框架。\\n4. 社区支持：OpenVINO有一个活跃的社区，开发者可以在这里分享经验、解决问题，并获取最新的开发工具和资源。\\n\\n通过使用OpenVINO，开发者可以轻松地将深度学习模型部署到边缘设备上，实现实时图像处理、语音识别、计算机视觉和自然语言处理等应用。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"<用户>什么是OpenVINO？<AI>\"\n",
    "pipe.generate(prompt, eos_token_id=2, max_length=500, streamer=streamer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
